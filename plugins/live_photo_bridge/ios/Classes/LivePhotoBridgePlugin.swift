import Flutter
import UIKit
import Photos
import AVFoundation
import ImageIO

public class LivePhotoBridgePlugin: NSObject, FlutterPlugin {
  private let imageManager = PHCachingImageManager()
  
  public static func register(with registrar: FlutterPluginRegistrar) {
    let channel = FlutterMethodChannel(name: "live_photo_bridge", binaryMessenger: registrar.messenger())
    let instance = LivePhotoBridgePlugin()
    registrar.addMethodCallDelegate(instance, channel: channel)
  }

  public func handle(_ call: FlutterMethodCall, result: @escaping FlutterResult) {
    switch call.method {
    case "getLivePhotoIds":
      getLivePhotoIds(result: result)
    case "getVideoPath":
      if let args = call.arguments as? [String: Any], 
         let assetId = args["assetId"] as? String {
        getVideoPath(assetId: assetId, result: result)
      } else {
        result(FlutterError(code: "INVALID_ARGS", message: "Asset ID is required", details: nil))
      }
    case "extractFrame":
      if let args = call.arguments as? [String: Any],
         let videoPath = args["videoPath"] as? String,
         let timeMs = args["timeMs"] as? Int {
        extractFrame(videoPath: videoPath, timeMs: timeMs, result: result)
      } else {
        result(FlutterError(code: "INVALID_ARGS", message: "videoPath and timeMs are required", details: nil))
      }
    case "createLivePhoto":
      if let args = call.arguments as? [String: Any],
         let frameImagePaths = args["frameImagePaths"] as? [String],
         let coverFrameIndex = args["coverFrameIndex"] as? Int {
        createLivePhoto(frameImagePaths: frameImagePaths, coverFrameIndex: coverFrameIndex, result: result)
      } else {
        result(FlutterError(code: "INVALID_ARGS", message: "frameImagePaths and coverFrameIndex are required", details: nil))
      }
    case "getVideoDuration":
      if let args = call.arguments as? [String: Any],
         let assetId = args["assetId"] as? String {
        getVideoDuration(assetId: assetId, result: result)
      } else {
        result(FlutterError(code: "INVALID_ARGS", message: "assetId is required", details: nil))
      }
    default:
      result(FlutterMethodNotImplemented)
    }
  }

  // èŽ·å–æ‰€æœ‰å®žå†µç…§ç‰‡ ID
  private func getLivePhotoIds(result: @escaping FlutterResult) {
    DispatchQueue.global(qos: .userInitiated).async {
      let fetchOptions = PHFetchOptions()
      
      fetchOptions.predicate = NSPredicate(
        format: "mediaType == %d && (mediaSubtype & %d) != 0",
        PHAssetMediaType.image.rawValue,
        PHAssetMediaSubtype.photoLive.rawValue
      )
      
      fetchOptions.sortDescriptors = [
        NSSortDescriptor(key: "creationDate", ascending: false)
      ]
      
      let fetchResult = PHAsset.fetchAssets(with: fetchOptions)
      var ids: [String] = []
      
      fetchResult.enumerateObjects { (asset, _, _) in
        if asset.mediaSubtypes.contains(.photoLive) {
          ids.append(asset.localIdentifier)
        }
      }
      
      DispatchQueue.main.async {
        print("âœ… iOSåŽŸç”Ÿ: æ‰¾åˆ° \(ids.count) å¼ å®žå†µç…§ç‰‡")
        result(ids)
      }
    }
  }

  // èŽ·å–å®žå†µç…§ç‰‡çš„è§†é¢‘éƒ¨åˆ†
  private func getVideoPath(assetId: String, result: @escaping FlutterResult) {
    print("ðŸŽ¬ iOSåŽŸç”Ÿ: å¼€å§‹èŽ·å–è§†é¢‘ \(assetId)")
    
    let fetchResult = PHAsset.fetchAssets(withLocalIdentifiers: [assetId], options: nil)
    
    guard let asset = fetchResult.firstObject else {
      print("âŒ iOSåŽŸç”Ÿ: æœªæ‰¾åˆ°èµ„æº")
      result(FlutterError(code: "NOT_FOUND", message: "Asset not found", details: nil))
      return
    }

    guard asset.mediaSubtypes.contains(.photoLive) else {
      print("âŒ iOSåŽŸç”Ÿ: ä¸æ˜¯å®žå†µç…§ç‰‡")
      result(FlutterError(code: "NOT_LIVE_PHOTO", message: "Not a Live Photo", details: nil))
      return
    }

    let options = PHLivePhotoRequestOptions()
    options.deliveryMode = .highQualityFormat
    options.isNetworkAccessAllowed = true
    
    print("ðŸ“¥ iOSåŽŸç”Ÿ: è¯·æ±‚ Live Photo èµ„æº")
    
    PHImageManager.default().requestLivePhoto(
      for: asset,
      targetSize: PHImageManagerMaximumSize,
      contentMode: .default,
      options: options
    ) { livePhoto, info in
      if let livePhoto = livePhoto {
        print("âœ… iOSåŽŸç”Ÿ: èŽ·å–åˆ° Live Photo å¯¹è±¡")
        self.extractVideoFromLivePhoto(livePhoto: livePhoto, assetId: assetId, result: result)
      } else if let error = info?[PHImageErrorKey] as? NSError {
        print("âŒ iOSåŽŸç”Ÿ: è¯·æ±‚å¤±è´¥ - \(error.localizedDescription)")
        result(FlutterError(
          code: "REQUEST_FAILED",
          message: error.localizedDescription,
          details: nil
        ))
      } else {
        print("âŒ iOSåŽŸç”Ÿ: æœªèŽ·å–åˆ° Live Photo")
        result(FlutterError(
          code: "NO_LIVE_PHOTO",
          message: "Failed to get Live Photo",
          details: nil
        ))
      }
    }
  }
  
  // ä»Ž PHLivePhoto æå–è§†é¢‘
  private func extractVideoFromLivePhoto(livePhoto: PHLivePhoto, assetId: String, result: @escaping FlutterResult) {
    DispatchQueue.global(qos: .userInitiated).async {
      let fetchResult = PHAsset.fetchAssets(withLocalIdentifiers: [assetId], options: nil)
      guard let asset = fetchResult.firstObject else {
        DispatchQueue.main.async {
          result(FlutterError(code: "NOT_FOUND", message: "Asset not found", details: nil))
        }
        return
      }
      
      let resources = PHAssetResource.assetResources(for: asset)
      guard let videoResource = resources.first(where: { $0.type == .pairedVideo }) else {
        DispatchQueue.main.async {
          result(FlutterError(code: "NO_VIDEO", message: "No paired video found", details: nil))
        }
        return
      }
      
      let tempDir = NSTemporaryDirectory()
      let timestamp = Int(Date().timeIntervalSince1970)
      let fileName = "live_\(timestamp)_\(arc4random_uniform(10000)).mov"
      let videoURL = URL(fileURLWithPath: tempDir).appendingPathComponent(fileName)
      
      try? FileManager.default.removeItem(at: videoURL)
      
      let options = PHAssetResourceRequestOptions()
      options.isNetworkAccessAllowed = true
      
      var lastProgress: Double = 0
      options.progressHandler = { progress in
        if progress - lastProgress >= 0.1 {
          print("ðŸ“¥ iOSåŽŸç”Ÿ: ä¸‹è½½è¿›åº¦ \(Int(progress * 100))%")
          lastProgress = progress
        }
      }
      
      print("ðŸ“¥ iOSåŽŸç”Ÿ: å¼€å§‹å¯¼å‡ºè§†é¢‘")
      
      PHAssetResourceManager.default().writeData(
        for: videoResource,
        toFile: videoURL,
        options: options
      ) { error in
        DispatchQueue.main.async {
          if let error = error {
            let nsError = error as NSError
            print("âŒ iOSåŽŸç”Ÿ: å¯¼å‡ºå¤±è´¥ - Code: \(nsError.code), Domain: \(nsError.domain)")
            
            var message = "è§†é¢‘å¯¼å‡ºå¤±è´¥"
            if nsError.domain == "PHPhotosErrorDomain" {
              switch nsError.code {
              case -1:
                message = "è§†é¢‘èµ„æºæš‚æ—¶ä¸å¯ç”¨ï¼Œå¯èƒ½æ­£åœ¨ä»ŽiCloudä¸‹è½½"
              case 3164:
                message = "éœ€è¦ç½‘ç»œè¿žæŽ¥æ¥ä¸‹è½½iCloudç…§ç‰‡"
              default:
                message = "PHPhotosé”™è¯¯ \(nsError.code): \(nsError.localizedDescription)"
              }
            }
            
            result(FlutterError(
              code: "EXPORT_FAILED",
              message: message,
              details: "Domain: \(nsError.domain), Code: \(nsError.code)"
            ))
          } else {
            print("âœ… iOSåŽŸç”Ÿ: è§†é¢‘å¯¼å‡ºæˆåŠŸ \(videoURL.path)")
            result(videoURL.path)
          }
        }
      }
    }
  }
  
  // ä»Žè§†é¢‘ä¸­æå–æŒ‡å®šæ—¶é—´ç‚¹çš„å¸§ï¼ˆä½¿ç”¨åŽŸå§‹åˆ†è¾¨çŽ‡ï¼Œä¸ç¼©æ”¾ï¼‰
  private func extractFrame(videoPath: String, timeMs: Int, result: @escaping FlutterResult) {
    print("ðŸŽ¬ iOSåŽŸç”Ÿ: å¼€å§‹æå–å¸§ - è§†é¢‘è·¯å¾„: \(videoPath), æ—¶é—´: \(timeMs)ms")
    
    DispatchQueue.global(qos: .userInitiated).async {
      let videoURL = URL(fileURLWithPath: videoPath)
      let asset = AVURLAsset(url: videoURL)
      let imageGenerator = AVAssetImageGenerator(asset: asset)
      imageGenerator.appliesPreferredTrackTransform = true
      imageGenerator.requestedTimeToleranceBefore = .zero
      imageGenerator.requestedTimeToleranceAfter = .zero
      
      let time = CMTime(value: Int64(timeMs), timescale: 1000)
      
      do {
        let cgImage = try imageGenerator.copyCGImage(at: time, actualTime: nil)
        // ä½¿ç”¨åŽŸå§‹åˆ†è¾¨çŽ‡ï¼Œä¸ç¼©æ”¾
        let uiImage = UIImage(cgImage: cgImage)
        
        guard let jpegData = uiImage.jpegData(compressionQuality: 0.95) else {
          DispatchQueue.main.async {
            result(FlutterError(code: "ENCODE_FAILED", message: "Failed to encode image", details: nil))
          }
          return
        }
        
        let tempDir = NSTemporaryDirectory()
        let timestamp = Int(Date().timeIntervalSince1970)
        let fileName = "frame_\(timestamp)_\(arc4random_uniform(10000)).jpg"
        let framePath = URL(fileURLWithPath: tempDir).appendingPathComponent(fileName)
        
        try jpegData.write(to: framePath)
        
        DispatchQueue.main.async {
          print("âœ… iOSåŽŸç”Ÿ: å¸§æå–æˆåŠŸ [\(cgImage.width)x\(cgImage.height)] - \(framePath.path)")
          result(framePath.path)
        }
      } catch {
        DispatchQueue.main.async {
          print("âŒ iOSåŽŸç”Ÿ: å¸§æå–å¤±è´¥ - \(error.localizedDescription)")
          result(FlutterError(code: "EXTRACTION_FAILED", message: error.localizedDescription, details: nil))
        }
      }
    }
  }
  
  // ðŸ”¥ èŽ·å– Live Photo è§†é¢‘çš„å®žé™…æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
  private func getVideoDuration(assetId: String, result: @escaping FlutterResult) {
    print("â±ï¸ iOSåŽŸç”Ÿ: èŽ·å–è§†é¢‘æ—¶é•¿ - \(assetId)")
    
    DispatchQueue.global(qos: .userInitiated).async {
      let fetchResult = PHAsset.fetchAssets(withLocalIdentifiers: [assetId], options: nil)
      
      guard let asset = fetchResult.firstObject else {
        DispatchQueue.main.async {
          result(FlutterError(code: "NOT_FOUND", message: "Asset not found", details: nil))
        }
        return
      }
      
      guard asset.mediaSubtypes.contains(.photoLive) else {
        DispatchQueue.main.async {
          result(0)
        }
        return
      }
      
      let resources = PHAssetResource.assetResources(for: asset)
      guard let videoResource = resources.first(where: { $0.type == .pairedVideo }) else {
        DispatchQueue.main.async {
          result(0)
        }
        return
      }
      
      let tempDir = NSTemporaryDirectory()
      let timestamp = Int(Date().timeIntervalSince1970)
      let fileName = "duration_check_\(timestamp).mov"
      let videoURL = URL(fileURLWithPath: tempDir).appendingPathComponent(fileName)
      
      try? FileManager.default.removeItem(at: videoURL)
      
      let options = PHAssetResourceRequestOptions()
      options.isNetworkAccessAllowed = true
      
      PHAssetResourceManager.default().writeData(
        for: videoResource,
        toFile: videoURL,
        options: options
      ) { error in
        if let error = error {
          DispatchQueue.main.async {
            print("âŒ iOSåŽŸç”Ÿ: èŽ·å–è§†é¢‘å¤±è´¥ - \(error.localizedDescription)")
            result(0)
          }
          return
        }
        
        let avAsset = AVURLAsset(url: videoURL)
        let duration = avAsset.duration
        let durationMs = Int(CMTimeGetSeconds(duration) * 1000)
        
        print("âœ… iOSåŽŸç”Ÿ: è§†é¢‘æ—¶é•¿ - \(durationMs)ms")
        
        try? FileManager.default.removeItem(at: videoURL)
        
        DispatchQueue.main.async {
          result(durationMs)
        }
      }
    }
  }
  
  // è°ƒæ•´å›¾ç‰‡å¤§å°ï¼ˆä»…åœ¨ createLivePhoto å°é¢åŽ‹ç¼©æ—¶ä½¿ç”¨ï¼‰
  private func resizeImage(image: UIImage, targetSize: CGSize) -> UIImage {
    let size = image.size
    let widthRatio  = targetSize.width  / size.width
    let heightRatio = targetSize.height / size.height
    let ratio = min(widthRatio, heightRatio)
    let newSize = CGSize(width: size.width * ratio, height: size.height * ratio)
    
    UIGraphicsBeginImageContextWithOptions(newSize, false, 1.0)
    image.draw(in: CGRect(origin: .zero, size: newSize))
    let newImage = UIGraphicsGetImageFromCurrentImageContext()
    UIGraphicsEndImageContext()
    
    return newImage ?? image
  }
  
  // ðŸ”¥ åˆ›å»º Live Photo å¹¶ä¿å­˜åˆ°å›¾åº“
  private func createLivePhoto(frameImagePaths: [String], coverFrameIndex: Int, result: @escaping FlutterResult) {
    print("ðŸŽ¬ iOSåŽŸç”Ÿ: å¼€å§‹åˆ›å»º Live Photo - æ€»å¸§æ•°: \(frameImagePaths.count), å°é¢å¸§: \(coverFrameIndex)")
    
    DispatchQueue.global(qos: .userInitiated).async {
      do {
        let tempDir = NSTemporaryDirectory()
        let timestamp = Int(Date().timeIntervalSince1970)
        
        // ç”Ÿæˆå”¯ä¸€æ ‡è¯†ç¬¦ç”¨äºŽ Live Photo é…å¯¹
        let assetIdentifier = UUID().uuidString
        print("ðŸ†” iOSåŽŸç”Ÿ: Live Photo æ ‡è¯†ç¬¦ - \(assetIdentifier)")
        
        // fps ä¸Ž createVideoFromFrames ä¿æŒä¸€è‡´
        let fps: Int32 = 15
        let safeIndex = min(coverFrameIndex, frameImagePaths.count - 1)
        
        // 1. å‡†å¤‡å°é¢å›¾ç‰‡
        let coverImagePath = frameImagePaths[safeIndex]
        guard let coverImage = UIImage(contentsOfFile: coverImagePath) else {
          throw NSError(domain: "LivePhotoBridge", code: -1, userInfo: [NSLocalizedDescriptionKey: "Failed to load cover image"])
        }
        
        let coverURL = URL(fileURLWithPath: tempDir).appendingPathComponent("live_puzzle_cover_\(timestamp).jpg")
        
        guard let imageData = coverImage.jpegData(compressionQuality: 0.95) else {
          throw NSError(domain: "LivePhotoBridge", code: -2, userInfo: [NSLocalizedDescriptionKey: "Failed to encode cover image"])
        }
        
        guard let source = CGImageSourceCreateWithData(imageData as CFData, nil),
              let imageType = CGImageSourceGetType(source) else {
          throw NSError(domain: "LivePhotoBridge", code: -3, userInfo: [NSLocalizedDescriptionKey: "Failed to create image source"])
        }
        
        guard let destination = CGImageDestinationCreateWithURL(coverURL as CFURL, imageType, 1, nil) else {
          throw NSError(domain: "LivePhotoBridge", code: -4, userInfo: [NSLocalizedDescriptionKey: "Failed to create image destination"])
        }
        
        guard let imageProperties = CGImageSourceCopyPropertiesAtIndex(source, 0, nil) as? [String: Any] else {
          throw NSError(domain: "LivePhotoBridge", code: -3, userInfo: [NSLocalizedDescriptionKey: "Failed to read image properties"])
        }
        
        var mutableProperties = imageProperties
        
        // ç”¨å®žé™… coverFrameIndex è®¡ç®— still image timeï¼ˆç§’ï¼‰
        let coverTimeSeconds = Double(safeIndex) / Double(fps)
        
        let makerApple: [String: Any] = [
          "17": assetIdentifier,                                       // Content Identifier - Live Photo é…å¯¹æ ‡è¯†ç¬¦
          "8": String(format: "%.6f", coverTimeSeconds)                // Still Image Timeï¼ˆç§’ï¼Œå­—ç¬¦ä¸²æ ¼å¼ï¼‰
        ]
        
        mutableProperties[kCGImagePropertyMakerAppleDictionary as String] = makerApple
        
        if let orientation = imageProperties[kCGImagePropertyOrientation as String] {
          mutableProperties[kCGImagePropertyOrientation as String] = orientation
        }
        
        print("ðŸ“ iOSåŽŸç”Ÿ: å°é¢å…ƒæ•°æ® - Identifier: \(assetIdentifier), StillTime: \(String(format: "%.6f", coverTimeSeconds))s")
        
        CGImageDestinationAddImageFromSource(destination, source, 0, mutableProperties as CFDictionary)
        
        guard CGImageDestinationFinalize(destination) else {
          throw NSError(domain: "LivePhotoBridge", code: -5, userInfo: [NSLocalizedDescriptionKey: "Failed to write image with metadata"])
        }
        
        print("âœ… iOSåŽŸç”Ÿ: å°é¢å›¾ç‰‡å‡†å¤‡å®Œæˆï¼ˆå¸¦å…ƒæ•°æ®ï¼‰")
        
        // 2. åˆ›å»ºè§†é¢‘ï¼ˆå¸¦æœ‰ Live Photo å…ƒæ•°æ® + timed metadata trackï¼‰
        print("ðŸ“¹ iOSåŽŸç”Ÿ: å¼€å§‹åˆ›å»ºè§†é¢‘...")
        let videoURL = URL(fileURLWithPath: tempDir).appendingPathComponent("live_puzzle_\(timestamp).mov")
        try self.createVideoFromFrames(
          framePaths: frameImagePaths,
          outputURL: videoURL,
          assetIdentifier: assetIdentifier,
          coverFrameIndex: safeIndex
        )
        print("âœ… iOSåŽŸç”Ÿ: è§†é¢‘åˆ›å»ºæˆåŠŸ - \(videoURL.path)")
        
        // 3. éªŒè¯æ–‡ä»¶å­˜åœ¨
        guard FileManager.default.fileExists(atPath: videoURL.path) else {
          throw NSError(domain: "LivePhotoBridge", code: -6, userInfo: [NSLocalizedDescriptionKey: "Video file not found"])
        }
        guard FileManager.default.fileExists(atPath: coverURL.path) else {
          throw NSError(domain: "LivePhotoBridge", code: -7, userInfo: [NSLocalizedDescriptionKey: "Cover file not found"])
        }
        
        // 4. æ£€æŸ¥ç›¸å†Œæƒé™
        let authStatus = PHPhotoLibrary.authorizationStatus()
        if authStatus != .authorized {
          print("âš ï¸ iOSåŽŸç”Ÿ: è¯·æ±‚ç›¸å†Œæƒé™...")
          let semaphore = DispatchSemaphore(value: 0)
          var granted = false
          
          PHPhotoLibrary.requestAuthorization { status in
            granted = (status == .authorized)
            semaphore.signal()
          }
          
          semaphore.wait()
          
          if !granted {
            throw NSError(domain: "LivePhotoBridge", code: -8, userInfo: [NSLocalizedDescriptionKey: "Photo library permission denied"])
          }
        }
        
        print("ðŸ“¸ iOSåŽŸç”Ÿ: å¼€å§‹ä¿å­˜åˆ°å›¾åº“...")
        
        // 5. åˆ›å»º Live Photo å¹¶ä¿å­˜åˆ°å›¾åº“
        var saveError: Error?
        let semaphore = DispatchSemaphore(value: 0)
        
        PHPhotoLibrary.shared().performChanges({
          let request = PHAssetCreationRequest.forAsset()
          request.addResource(with: .photo, fileURL: coverURL, options: nil)
          
          let videoOptions = PHAssetResourceCreationOptions()
          videoOptions.shouldMoveFile = false
          request.addResource(with: .pairedVideo, fileURL: videoURL, options: videoOptions)
          
          print("âœ… iOSåŽŸç”Ÿ: èµ„æºå·²æ·»åŠ åˆ°åˆ›å»ºè¯·æ±‚")
          
        }) { success, error in
          if let error = error {
            let nsError = error as NSError
            print("âŒ iOSåŽŸç”Ÿ: ä¿å­˜å¤±è´¥ - Code: \(nsError.code), \(nsError.localizedDescription)")
            saveError = error
          } else if success {
            print("âœ… iOSåŽŸç”Ÿ: Live Photo ä¿å­˜æˆåŠŸ")
          }
          semaphore.signal()
        }
        
        semaphore.wait()
        
        try? FileManager.default.removeItem(at: videoURL)
        try? FileManager.default.removeItem(at: coverURL)
        
        DispatchQueue.main.async {
          if let error = saveError {
            result(FlutterError(
              code: "SAVE_FAILED",
              message: error.localizedDescription,
              details: nil
            ))
          } else {
            result(true)
          }
        }
        
      } catch {
        DispatchQueue.main.async {
          print("âŒ iOSåŽŸç”Ÿ: åˆ›å»º Live Photo å¤±è´¥ - \(error.localizedDescription)")
          result(FlutterError(code: "CREATE_FAILED", message: error.localizedDescription, details: nil))
        }
      }
    }
  }
  
  // ðŸ”¥ ä»Žå›¾ç‰‡å¸§åˆ›å»ºè§†é¢‘ï¼ˆåŒ…å« timed metadata track ä»¥æ”¯æŒ still-image-timeï¼‰
  private func createVideoFromFrames(
    framePaths: [String],
    outputURL: URL,
    assetIdentifier: String,
    coverFrameIndex: Int
  ) throws {
    guard !framePaths.isEmpty else {
      throw NSError(domain: "LivePhotoBridge", code: -1, userInfo: [NSLocalizedDescriptionKey: "No frames provided"])
    }
    
    guard let firstImage = UIImage(contentsOfFile: framePaths[0]) else {
      throw NSError(domain: "LivePhotoBridge", code: -2, userInfo: [NSLocalizedDescriptionKey: "Failed to load first frame"])
    }
    
    let videoSize = firstImage.size
    print("ðŸ“ iOSåŽŸç”Ÿ: è§†é¢‘å°ºå¯¸ - \(videoSize.width) x \(videoSize.height)")
    
    // Live Photo è§†é¢‘è§„èŒƒï¼š30 å¸§ / 15fps = 2 ç§’
    let fps: Int32 = 15
    let frameDuration = CMTime(value: 1, timescale: fps)
    
    try? FileManager.default.removeItem(at: outputURL)
    
    let writer = try AVAssetWriter(outputURL: outputURL, fileType: .mov)
    
    // â”€â”€ å®¹å™¨çº§å…ƒæ•°æ®ï¼šä»…ä¿ç•™ content.identifier â”€â”€
    let contentIdItem = AVMutableMetadataItem()
    contentIdItem.key = "com.apple.quicktime.content.identifier" as NSString
    contentIdItem.keySpace = AVMetadataKeySpace.quickTimeMetadata
    contentIdItem.value = assetIdentifier as NSString
    contentIdItem.dataType = "com.apple.metadata.datatype.UTF-8"
    writer.metadata = [contentIdItem]
    
    // â”€â”€ è§†é¢‘è½¨é“ï¼ˆæå‡ç çŽ‡åˆ° 10 Mbpsï¼ŒHigh profileï¼ŒBGRA åƒç´ æ ¼å¼ï¼‰â”€â”€
    let videoSettings: [String: Any] = [
      AVVideoCodecKey: AVVideoCodecType.h264,
      AVVideoWidthKey: Int(videoSize.width),
      AVVideoHeightKey: Int(videoSize.height),
      AVVideoCompressionPropertiesKey: [
        AVVideoAverageBitRateKey: 10_000_000,
        AVVideoProfileLevelKey: AVVideoProfileLevelH264HighAutoLevel
      ]
    ]
    
    let writerInput = AVAssetWriterInput(mediaType: .video, outputSettings: videoSettings)
    writerInput.expectsMediaDataInRealTime = false
    
    let adaptor = AVAssetWriterInputPixelBufferAdaptor(
      assetWriterInput: writerInput,
      sourcePixelBufferAttributes: [
        kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA,
        kCVPixelBufferWidthKey as String: Int(videoSize.width),
        kCVPixelBufferHeightKey as String: Int(videoSize.height)
      ]
    )
    
    guard writer.canAdd(writerInput) else {
      throw NSError(domain: "LivePhotoBridge", code: -3, userInfo: [NSLocalizedDescriptionKey: "Cannot add video writer input"])
    }
    writer.add(writerInput)
    
    // â”€â”€ Timed metadata trackï¼ˆstill-image-timeï¼ŒiOS Photos è¦æ±‚ï¼‰â”€â”€
    let metaSpec: [String: Any] = [
      kCMMetadataFormatDescriptionMetadataSpecificationKey_Identifier as String:
        "mdta/com.apple.quicktime.still-image-time",
      kCMMetadataFormatDescriptionMetadataSpecificationKey_DataType as String:
        "com.apple.metadata.datatype.int8"
    ]
    var metaFormatDesc: CMFormatDescription?
    CMMetadataFormatDescriptionCreateWithMetadataSpecifications(
      allocator: kCFAllocatorDefault,
      metadataType: kCMMetadataFormatType_Boxed,
      metadataSpecifications: [metaSpec] as CFArray,
      formatDescriptionOut: &metaFormatDesc
    )
    
    let metaInput = AVAssetWriterInput(
      mediaType: .metadata,
      outputSettings: nil,
      sourceFormatHint: metaFormatDesc
    )
    metaInput.expectsMediaDataInRealTime = false
    let metaAdaptor = AVAssetWriterInputMetadataAdaptor(assetWriterInput: metaInput)
    
    guard writer.canAdd(metaInput) else {
      throw NSError(domain: "LivePhotoBridge", code: -3, userInfo: [NSLocalizedDescriptionKey: "Cannot add metadata writer input"])
    }
    writer.add(metaInput)
    
    writer.startWriting()
    writer.startSession(atSourceTime: .zero)
    
    // â”€â”€ åœ¨ coverFrameIndex å¯¹åº”æ—¶é—´ç‚¹å†™å…¥ still-image-time â”€â”€
    let coverTime = CMTimeMultiply(frameDuration, multiplier: Int32(coverFrameIndex))
    let coverRange = CMTimeRange(start: coverTime, duration: frameDuration)
    let stillItem = AVMutableMetadataItem()
    stillItem.key = "com.apple.quicktime.still-image-time" as NSString
    stillItem.keySpace = AVMetadataKeySpace.quickTimeMetadata
    stillItem.value = NSNumber(value: 0)  // å€¼æœ¬èº«æ— æ„ä¹‰ï¼Œæ—¶é—´ç”± presentationTime å†³å®š
    stillItem.dataType = "com.apple.metadata.datatype.int8"
    let metaGroup = AVTimedMetadataGroup(items: [stillItem], timeRange: coverRange)
    metaAdaptor.append(metaGroup)
    metaInput.markAsFinished()
    
    print("ðŸ“¹ iOSåŽŸç”Ÿ: å¼€å§‹å†™å…¥ \(framePaths.count) å¸§ï¼Œå°é¢å¸§: \(coverFrameIndex)...")
    
    var frameCount: Int64 = 0
    
    for (index, framePath) in framePaths.enumerated() {
      autoreleasepool {
        guard let image = UIImage(contentsOfFile: framePath) else {
          print("âš ï¸ iOSåŽŸç”Ÿ: è·³è¿‡å¸§ \(index) - æ— æ³•åŠ è½½")
          return
        }
        
        guard let pixelBuffer = self.pixelBuffer(from: image, size: videoSize) else {
          print("âš ï¸ iOSåŽŸç”Ÿ: è·³è¿‡å¸§ \(index) - æ— æ³•åˆ›å»º PixelBuffer")
          return
        }
        
        while !writerInput.isReadyForMoreMediaData {
          Thread.sleep(forTimeInterval: 0.01)
        }
        
        let presentationTime = CMTimeMultiply(frameDuration, multiplier: Int32(frameCount))
        
        if adaptor.append(pixelBuffer, withPresentationTime: presentationTime) {
          frameCount += 1
          if index % 10 == 0 {
            print("ðŸ“¹ iOSåŽŸç”Ÿ: å·²å†™å…¥ \(frameCount) å¸§")
          }
        } else {
          print("âš ï¸ iOSåŽŸç”Ÿ: æ·»åŠ å¸§ \(index) å¤±è´¥")
        }
      }
    }
    
    print("ðŸ“¹ iOSåŽŸç”Ÿ: å®Œæˆå†™å…¥ \(frameCount) å¸§ï¼Œæ­£åœ¨ç»“æŸ...")
    
    writerInput.markAsFinished()
    
    let semaphore = DispatchSemaphore(value: 0)
    var finishError: Error?
    
    writer.finishWriting {
      finishError = writer.error
      semaphore.signal()
    }
    
    semaphore.wait()
    
    if let error = finishError {
      throw error
    }
    
    if writer.status != .completed {
      throw NSError(domain: "LivePhotoBridge", code: -4, userInfo: [NSLocalizedDescriptionKey: "Video writing did not complete, status: \(writer.status.rawValue)"])
    }
    
    let fileSize = try FileManager.default.attributesOfItem(atPath: outputURL.path)[.size] as? UInt64 ?? 0
    print("âœ… iOSåŽŸç”Ÿ: è§†é¢‘åˆ›å»ºæˆåŠŸ - å¤§å°: \(fileSize) bytes, å¸§æ•°: \(frameCount)")
    
    if fileSize == 0 {
      throw NSError(domain: "LivePhotoBridge", code: -5, userInfo: [NSLocalizedDescriptionKey: "Video file is empty"])
    }
  }
  
  // ðŸ”¥ å°† UIImage è½¬æ¢ä¸º CVPixelBufferï¼ˆä½¿ç”¨ BGRA æ ¼å¼ï¼Œä¸Ž CG drawing åŒ¹é…ï¼‰
  private func pixelBuffer(from image: UIImage, size: CGSize) -> CVPixelBuffer? {
    let attrs = [
      kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue!,
      kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue!
    ] as CFDictionary
    
    var pixelBuffer: CVPixelBuffer?
    let status = CVPixelBufferCreate(
      kCFAllocatorDefault,
      Int(size.width),
      Int(size.height),
      kCVPixelFormatType_32BGRA,
      attrs,
      &pixelBuffer
    )
    
    guard status == kCVReturnSuccess, let buffer = pixelBuffer else {
      return nil
    }
    
    CVPixelBufferLockBaseAddress(buffer, [])
    defer { CVPixelBufferUnlockBaseAddress(buffer, []) }
    
    let context = CGContext(
      data: CVPixelBufferGetBaseAddress(buffer),
      width: Int(size.width),
      height: Int(size.height),
      bitsPerComponent: 8,
      bytesPerRow: CVPixelBufferGetBytesPerRow(buffer),
      space: CGColorSpaceCreateDeviceRGB(),
      bitmapInfo: CGImageAlphaInfo.premultipliedFirst.rawValue | CGBitmapInfo.byteOrder32Little.rawValue
    )
    
    guard let cgContext = context, let cgImage = image.cgImage else {
      return nil
    }
    
    cgContext.draw(cgImage, in: CGRect(origin: .zero, size: size))
    
    return buffer
  }
}
