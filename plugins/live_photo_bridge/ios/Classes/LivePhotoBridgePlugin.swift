import Flutter
import UIKit
import Photos
import AVFoundation
import ImageIO

public class LivePhotoBridgePlugin: NSObject, FlutterPlugin {
  private let imageManager = PHCachingImageManager()
  
  public static func register(with registrar: FlutterPluginRegistrar) {
    let channel = FlutterMethodChannel(name: "live_photo_bridge", binaryMessenger: registrar.messenger())
    let instance = LivePhotoBridgePlugin()
    registrar.addMethodCallDelegate(instance, channel: channel)
  }

  public func handle(_ call: FlutterMethodCall, result: @escaping FlutterResult) {
    switch call.method {
    case "getLivePhotoIds":
      getLivePhotoIds(result: result)
    case "getVideoPath":
      if let args = call.arguments as? [String: Any], 
         let assetId = args["assetId"] as? String {
        getVideoPath(assetId: assetId, result: result)
      } else {
        result(FlutterError(code: "INVALID_ARGS", message: "Asset ID is required", details: nil))
      }
    case "extractFrame":
      if let args = call.arguments as? [String: Any],
         let videoPath = args["videoPath"] as? String,
         let timeMs = args["timeMs"] as? Int {
        extractFrame(videoPath: videoPath, timeMs: timeMs, result: result)
      } else {
        result(FlutterError(code: "INVALID_ARGS", message: "videoPath and timeMs are required", details: nil))
      }
    case "createLivePhoto":
      if let args = call.arguments as? [String: Any],
         let frameImagePaths = args["frameImagePaths"] as? [String],
         let coverFrameIndex = args["coverFrameIndex"] as? Int {
        createLivePhoto(frameImagePaths: frameImagePaths, coverFrameIndex: coverFrameIndex, result: result)
      } else {
        result(FlutterError(code: "INVALID_ARGS", message: "frameImagePaths and coverFrameIndex are required", details: nil))
      }
    case "getVideoDuration":
      if let args = call.arguments as? [String: Any],
         let assetId = args["assetId"] as? String {
        getVideoDuration(assetId: assetId, result: result)
      } else {
        result(FlutterError(code: "INVALID_ARGS", message: "assetId is required", details: nil))
      }
    default:
      result(FlutterMethodNotImplemented)
    }
  }

  // èŽ·å–æ‰€æœ‰å®žå†µç…§ç‰‡ ID
  private func getLivePhotoIds(result: @escaping FlutterResult) {
    DispatchQueue.global(qos: .userInitiated).async {
      let fetchOptions = PHFetchOptions()
      
      // æ ¸å¿ƒè¯†åˆ«ï¼šä½¿ç”¨ mediaSubtype è¿‡æ»¤å®žå†µç…§ç‰‡
      fetchOptions.predicate = NSPredicate(
        format: "mediaType == %d && (mediaSubtype & %d) != 0",
        PHAssetMediaType.image.rawValue,
        PHAssetMediaSubtype.photoLive.rawValue
      )
      
      // æŒ‰åˆ›å»ºæ—¶é—´å€’åº
      fetchOptions.sortDescriptors = [
        NSSortDescriptor(key: "creationDate", ascending: false)
      ]
      
      let fetchResult = PHAsset.fetchAssets(with: fetchOptions)
      var ids: [String] = []
      
      fetchResult.enumerateObjects { (asset, _, _) in
        // äºŒæ¬¡ç¡®è®¤æ˜¯å¦ä¸ºå®žå†µç…§ç‰‡
        if asset.mediaSubtypes.contains(.photoLive) {
          ids.append(asset.localIdentifier)
        }
      }
      
      DispatchQueue.main.async {
        print("âœ… iOSåŽŸç”Ÿ: æ‰¾åˆ° \(ids.count) å¼ å®žå†µç…§ç‰‡")
        result(ids)
      }
    }
  }

  // èŽ·å–å®žå†µç…§ç‰‡çš„è§†é¢‘éƒ¨åˆ†
  private func getVideoPath(assetId: String, result: @escaping FlutterResult) {
    print("ðŸŽ¬ iOSåŽŸç”Ÿ: å¼€å§‹èŽ·å–è§†é¢‘ \(assetId)")
    
    let fetchResult = PHAsset.fetchAssets(withLocalIdentifiers: [assetId], options: nil)
    
    guard let asset = fetchResult.firstObject else {
      print("âŒ iOSåŽŸç”Ÿ: æœªæ‰¾åˆ°èµ„æº")
      result(FlutterError(code: "NOT_FOUND", message: "Asset not found", details: nil))
      return
    }

    // æ£€æŸ¥æ˜¯å¦ä¸ºå®žå†µç…§ç‰‡
    guard asset.mediaSubtypes.contains(.photoLive) else {
      print("âŒ iOSåŽŸç”Ÿ: ä¸æ˜¯å®žå†µç…§ç‰‡")
      result(FlutterError(code: "NOT_LIVE_PHOTO", message: "Not a Live Photo", details: nil))
      return
    }

    // ä½¿ç”¨ PHLivePhoto æ–¹å¼èŽ·å–è§†é¢‘
    let options = PHLivePhotoRequestOptions()
    options.deliveryMode = .highQualityFormat
    options.isNetworkAccessAllowed = true
    
    print("ðŸ“¥ iOSåŽŸç”Ÿ: è¯·æ±‚ Live Photo èµ„æº")
    
    PHImageManager.default().requestLivePhoto(
      for: asset,
      targetSize: PHImageManagerMaximumSize,
      contentMode: .default,
      options: options
    ) { livePhoto, info in
      if let livePhoto = livePhoto {
        print("âœ… iOSåŽŸç”Ÿ: èŽ·å–åˆ° Live Photo å¯¹è±¡")
        self.extractVideoFromLivePhoto(livePhoto: livePhoto, assetId: assetId, result: result)
      } else if let error = info?[PHImageErrorKey] as? NSError {
        print("âŒ iOSåŽŸç”Ÿ: è¯·æ±‚å¤±è´¥ - \(error.localizedDescription)")
        result(FlutterError(
          code: "REQUEST_FAILED",
          message: error.localizedDescription,
          details: nil
        ))
      } else {
        print("âŒ iOSåŽŸç”Ÿ: æœªèŽ·å–åˆ° Live Photo")
        result(FlutterError(
          code: "NO_LIVE_PHOTO",
          message: "Failed to get Live Photo",
          details: nil
        ))
      }
    }
  }
  
  // ä»Ž PHLivePhoto æå–è§†é¢‘
  private func extractVideoFromLivePhoto(livePhoto: PHLivePhoto, assetId: String, result: @escaping FlutterResult) {
    // æ–¹æ³•1: å°è¯•é€šè¿‡ PHAssetResource å¯¼å‡ºï¼ˆä½¿ç”¨å¼‚æ­¥é˜Ÿåˆ—é¿å…é˜»å¡žï¼‰
    DispatchQueue.global(qos: .userInitiated).async {
      let fetchResult = PHAsset.fetchAssets(withLocalIdentifiers: [assetId], options: nil)
      guard let asset = fetchResult.firstObject else {
        DispatchQueue.main.async {
          result(FlutterError(code: "NOT_FOUND", message: "Asset not found", details: nil))
        }
        return
      }
      
      let resources = PHAssetResource.assetResources(for: asset)
      guard let videoResource = resources.first(where: { $0.type == .pairedVideo }) else {
        DispatchQueue.main.async {
          result(FlutterError(code: "NO_VIDEO", message: "No paired video found", details: nil))
        }
        return
      }
      
      // åˆ›å»ºå”¯ä¸€çš„ä¸´æ—¶æ–‡ä»¶
      let tempDir = NSTemporaryDirectory()
      let timestamp = Int(Date().timeIntervalSince1970)
      let fileName = "live_\(timestamp)_\(arc4random_uniform(10000)).mov"
      let videoURL = URL(fileURLWithPath: tempDir).appendingPathComponent(fileName)
      
      // åˆ é™¤å¯èƒ½å­˜åœ¨çš„æ—§æ–‡ä»¶
      try? FileManager.default.removeItem(at: videoURL)
      
      let options = PHAssetResourceRequestOptions()
      options.isNetworkAccessAllowed = true
      
      // æ·»åŠ è¿›åº¦å›žè°ƒ
      var lastProgress: Double = 0
      options.progressHandler = { progress in
        if progress - lastProgress >= 0.1 {
          print("ðŸ“¥ iOSåŽŸç”Ÿ: ä¸‹è½½è¿›åº¦ \(Int(progress * 100))%")
          lastProgress = progress
        }
      }
      
      print("ðŸ“¥ iOSåŽŸç”Ÿ: å¼€å§‹å¯¼å‡ºè§†é¢‘")
      
      PHAssetResourceManager.default().writeData(
        for: videoResource,
        toFile: videoURL,
        options: options
      ) { error in
        DispatchQueue.main.async {
          if let error = error {
            let nsError = error as NSError
            print("âŒ iOSåŽŸç”Ÿ: å¯¼å‡ºå¤±è´¥ - Code: \(nsError.code), Domain: \(nsError.domain)")
            print("âŒ iOSåŽŸç”Ÿ: \(nsError.localizedDescription)")
            
            // æä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
            var message = "è§†é¢‘å¯¼å‡ºå¤±è´¥"
            if nsError.domain == "PHPhotosErrorDomain" {
              switch nsError.code {
              case -1:
                message = "è§†é¢‘èµ„æºæš‚æ—¶ä¸å¯ç”¨ï¼Œå¯èƒ½æ­£åœ¨ä»ŽiCloudä¸‹è½½"
              case 3164:
                message = "éœ€è¦ç½‘ç»œè¿žæŽ¥æ¥ä¸‹è½½iCloudç…§ç‰‡"
              default:
                message = "PHPhotosé”™è¯¯ \(nsError.code): \(nsError.localizedDescription)"
              }
            }
            
            result(FlutterError(
              code: "EXPORT_FAILED",
              message: message,
              details: "Domain: \(nsError.domain), Code: \(nsError.code)"
            ))
          } else {
            print("âœ… iOSåŽŸç”Ÿ: è§†é¢‘å¯¼å‡ºæˆåŠŸ \(videoURL.path)")
            result(videoURL.path)
          }
        }
      }
    }
  }
  
  // ä»Žè§†é¢‘ä¸­æå–æŒ‡å®šæ—¶é—´ç‚¹çš„å¸§
  private func extractFrame(videoPath: String, timeMs: Int, result: @escaping FlutterResult) {
    print("ðŸŽ¬ iOSåŽŸç”Ÿ: å¼€å§‹æå–å¸§ - è§†é¢‘è·¯å¾„: \(videoPath), æ—¶é—´: \(timeMs)ms")
    
    DispatchQueue.global(qos: .userInitiated).async {
      let videoURL = URL(fileURLWithPath: videoPath)
      let asset = AVURLAsset(url: videoURL)
      let imageGenerator = AVAssetImageGenerator(asset: asset)
      imageGenerator.appliesPreferredTrackTransform = true
      imageGenerator.requestedTimeToleranceBefore = .zero
      imageGenerator.requestedTimeToleranceAfter = .zero
      
      let time = CMTime(value: Int64(timeMs), timescale: 1000)
      
      do {
        let cgImage = try imageGenerator.copyCGImage(at: time, actualTime: nil)
        let uiImage = UIImage(cgImage: cgImage)
        
        // ðŸ”¥ æé«˜åˆ†è¾¨çŽ‡ï¼šä¿æŒè¾ƒé«˜è´¨é‡ç”¨äºŽæ‹¼å›¾
        let targetSize = CGSize(width: 1200, height: 1200)
        let resizedImage = self.resizeImage(image: uiImage, targetSize: targetSize)
        
        // ðŸ”¥ æé«˜JPEGè´¨é‡
        guard let jpegData = resizedImage.jpegData(compressionQuality: 0.95) else {
          DispatchQueue.main.async {
            result(FlutterError(code: "ENCODE_FAILED", message: "Failed to encode image", details: nil))
          }
          return
        }
        
        // ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        let tempDir = NSTemporaryDirectory()
        let timestamp = Int(Date().timeIntervalSince1970)
        let fileName = "frame_\(timestamp)_\(arc4random_uniform(10000)).jpg"
        let framePath = URL(fileURLWithPath: tempDir).appendingPathComponent(fileName)
        
        try jpegData.write(to: framePath)
        
        DispatchQueue.main.async {
          print("âœ… iOSåŽŸç”Ÿ: å¸§æå–æˆåŠŸ - \(framePath.path)")
          result(framePath.path)
        }
      } catch {
        DispatchQueue.main.async {
          print("âŒ iOSåŽŸç”Ÿ: å¸§æå–å¤±è´¥ - \(error.localizedDescription)")
          result(FlutterError(code: "EXTRACTION_FAILED", message: error.localizedDescription, details: nil))
        }
      }
    }
  }
  
  // ðŸ”¥ èŽ·å– Live Photo è§†é¢‘çš„å®žé™…æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
  private func getVideoDuration(assetId: String, result: @escaping FlutterResult) {
    print("â±ï¸ iOSåŽŸç”Ÿ: èŽ·å–è§†é¢‘æ—¶é•¿ - \(assetId)")
    
    DispatchQueue.global(qos: .userInitiated).async {
      let fetchResult = PHAsset.fetchAssets(withLocalIdentifiers: [assetId], options: nil)
      
      guard let asset = fetchResult.firstObject else {
        DispatchQueue.main.async {
          result(FlutterError(code: "NOT_FOUND", message: "Asset not found", details: nil))
        }
        return
      }
      
      guard asset.mediaSubtypes.contains(.photoLive) else {
        DispatchQueue.main.async {
          result(0) // ä¸æ˜¯ Live Photoï¼Œè¿”å›ž 0
        }
        return
      }
      
      // èŽ·å–è§†é¢‘è·¯å¾„
      let resources = PHAssetResource.assetResources(for: asset)
      guard let videoResource = resources.first(where: { $0.type == .pairedVideo }) else {
        DispatchQueue.main.async {
          result(0)
        }
        return
      }
      
      // å¯¼å‡ºè§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶ä»¥èŽ·å–æ—¶é•¿
      let tempDir = NSTemporaryDirectory()
      let timestamp = Int(Date().timeIntervalSince1970)
      let fileName = "duration_check_\(timestamp).mov"
      let videoURL = URL(fileURLWithPath: tempDir).appendingPathComponent(fileName)
      
      try? FileManager.default.removeItem(at: videoURL)
      
      let options = PHAssetResourceRequestOptions()
      options.isNetworkAccessAllowed = true
      
      PHAssetResourceManager.default().writeData(
        for: videoResource,
        toFile: videoURL,
        options: options
      ) { error in
        if let error = error {
          DispatchQueue.main.async {
            print("âŒ iOSåŽŸç”Ÿ: èŽ·å–è§†é¢‘å¤±è´¥ - \(error.localizedDescription)")
            result(0)
          }
          return
        }
        
        // ä½¿ç”¨ AVAsset èŽ·å–æ—¶é•¿
        let avAsset = AVURLAsset(url: videoURL)
        let duration = avAsset.duration
        let durationMs = Int(CMTimeGetSeconds(duration) * 1000)
        
        print("âœ… iOSåŽŸç”Ÿ: è§†é¢‘æ—¶é•¿ - \(durationMs)ms")
        
        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try? FileManager.default.removeItem(at: videoURL)
        
        DispatchQueue.main.async {
          result(durationMs)
        }
      }
    }
  }
  
  // è°ƒæ•´å›¾ç‰‡å¤§å°
  private func resizeImage(image: UIImage, targetSize: CGSize) -> UIImage {
    let size = image.size
    let widthRatio  = targetSize.width  / size.width
    let heightRatio = targetSize.height / size.height
    let ratio = min(widthRatio, heightRatio)
    let newSize = CGSize(width: size.width * ratio, height: size.height * ratio)
    
    UIGraphicsBeginImageContextWithOptions(newSize, false, 1.0)
    image.draw(in: CGRect(origin: .zero, size: newSize))
    let newImage = UIGraphicsGetImageFromCurrentImageContext()
    UIGraphicsEndImageContext()
    
    return newImage ?? image
  }
  
  // ðŸ”¥ åˆ›å»º Live Photo å¹¶ä¿å­˜åˆ°å›¾åº“
  private func createLivePhoto(frameImagePaths: [String], coverFrameIndex: Int, result: @escaping FlutterResult) {
    print("ðŸŽ¬ iOSåŽŸç”Ÿ: å¼€å§‹åˆ›å»º Live Photo - æ€»å¸§æ•°: \(frameImagePaths.count), å°é¢å¸§: \(coverFrameIndex)")
    
    DispatchQueue.global(qos: .userInitiated).async {
      do {
        let tempDir = NSTemporaryDirectory()
        let timestamp = Int(Date().timeIntervalSince1970)
        
        // ðŸ”¥ ç”Ÿæˆå”¯ä¸€æ ‡è¯†ç¬¦ç”¨äºŽ Live Photo é…å¯¹
        let assetIdentifier = UUID().uuidString
        print("ðŸ†” iOSåŽŸç”Ÿ: Live Photo æ ‡è¯†ç¬¦ - \(assetIdentifier)")
        
        // 1. å‡†å¤‡å°é¢å›¾ç‰‡ï¼ˆå…ˆå‡†å¤‡å›¾ç‰‡ï¼Œå› ä¸ºéœ€è¦å†™å…¥å…ƒæ•°æ®ï¼‰
        let coverImagePath = frameImagePaths[min(coverFrameIndex, frameImagePaths.count - 1)]
        guard let coverImage = UIImage(contentsOfFile: coverImagePath) else {
          throw NSError(domain: "LivePhotoBridge", code: -1, userInfo: [NSLocalizedDescriptionKey: "Failed to load cover image"])
        }
        
        let coverURL = URL(fileURLWithPath: tempDir).appendingPathComponent("live_puzzle_cover_\(timestamp).jpg")
        
        // ðŸ”¥ å†™å…¥å¸¦æœ‰ Live Photo å…ƒæ•°æ®çš„å›¾ç‰‡
        guard let imageData = coverImage.jpegData(compressionQuality: 0.95) else {
          throw NSError(domain: "LivePhotoBridge", code: -2, userInfo: [NSLocalizedDescriptionKey: "Failed to encode cover image"])
        }
        
        // æ·»åŠ  Live Photo å…ƒæ•°æ®åˆ°å›¾ç‰‡
        guard let source = CGImageSourceCreateWithData(imageData as CFData, nil),
              let imageType = CGImageSourceGetType(source) else {
          throw NSError(domain: "LivePhotoBridge", code: -3, userInfo: [NSLocalizedDescriptionKey: "Failed to create image source"])
        }
        
        guard let destination = CGImageDestinationCreateWithURL(coverURL as CFURL, imageType, 1, nil) else {
          throw NSError(domain: "LivePhotoBridge", code: -4, userInfo: [NSLocalizedDescriptionKey: "Failed to create image destination"])
        }
        
        // ðŸ”¥ æ·»åŠ  Live Photo æ ‡è¯†å…ƒæ•°æ®
        let metadata: [String: Any] = [
          kCGImagePropertyMakerAppleDictionary as String: [
            "17": assetIdentifier  // Live Photo é…å¯¹æ ‡è¯†ç¬¦
          ]
        ]
        
        CGImageDestinationAddImageFromSource(destination, source, 0, metadata as CFDictionary)
        
        guard CGImageDestinationFinalize(destination) else {
          throw NSError(domain: "LivePhotoBridge", code: -5, userInfo: [NSLocalizedDescriptionKey: "Failed to write image with metadata"])
        }
        
        print("âœ… iOSåŽŸç”Ÿ: å°é¢å›¾ç‰‡å‡†å¤‡å®Œæˆï¼ˆå¸¦å…ƒæ•°æ®ï¼‰")
        
        // 2. åˆ›å»ºè§†é¢‘ï¼ˆå¸¦æœ‰ Live Photo å…ƒæ•°æ®ï¼‰
        print("ðŸ“¹ iOSåŽŸç”Ÿ: å¼€å§‹åˆ›å»ºè§†é¢‘...")
        let videoURL = URL(fileURLWithPath: tempDir).appendingPathComponent("live_puzzle_\(timestamp).mov")
        try self.createVideoFromFrames(framePaths: frameImagePaths, outputURL: videoURL, assetIdentifier: assetIdentifier)
        print("âœ… iOSåŽŸç”Ÿ: è§†é¢‘åˆ›å»ºæˆåŠŸ - \(videoURL.path)")
        
        // 3. éªŒè¯æ–‡ä»¶å­˜åœ¨
        guard FileManager.default.fileExists(atPath: videoURL.path) else {
          throw NSError(domain: "LivePhotoBridge", code: -6, userInfo: [NSLocalizedDescriptionKey: "Video file not found"])
        }
        guard FileManager.default.fileExists(atPath: coverURL.path) else {
          throw NSError(domain: "LivePhotoBridge", code: -7, userInfo: [NSLocalizedDescriptionKey: "Cover file not found"])
        }
        
        // 4. æ£€æŸ¥ç›¸å†Œæƒé™ï¼ˆä½¿ç”¨å…¼å®¹ iOS 13 çš„ APIï¼‰
        let authStatus = PHPhotoLibrary.authorizationStatus()
        if authStatus != .authorized {
          print("âš ï¸ iOSåŽŸç”Ÿ: è¯·æ±‚ç›¸å†Œæƒé™...")
          let semaphore = DispatchSemaphore(value: 0)
          var granted = false
          
          PHPhotoLibrary.requestAuthorization { status in
            granted = (status == .authorized)
            semaphore.signal()
          }
          
          semaphore.wait()
          
          if !granted {
            throw NSError(domain: "LivePhotoBridge", code: -8, userInfo: [NSLocalizedDescriptionKey: "Photo library permission denied"])
          }
        }
        
        print("ðŸ“¸ iOSåŽŸç”Ÿ: å¼€å§‹ä¿å­˜åˆ°å›¾åº“...")
        
        // 5. åˆ›å»º Live Photo å¹¶ä¿å­˜åˆ°å›¾åº“
        var saveError: Error?
        let semaphore = DispatchSemaphore(value: 0)
        
        PHPhotoLibrary.shared().performChanges({
          let request = PHAssetCreationRequest.forAsset()
          
          // æ·»åŠ å›¾ç‰‡èµ„æºï¼ˆä½œä¸ºä¸»å›¾ç‰‡ï¼‰
          request.addResource(with: .photo, fileURL: coverURL, options: nil)
          
          // æ·»åŠ é…å¯¹è§†é¢‘èµ„æºï¼ˆä½œä¸º Live Photo çš„åŠ¨ç”»éƒ¨åˆ†ï¼‰
          let videoOptions = PHAssetResourceCreationOptions()
          videoOptions.shouldMoveFile = false
          request.addResource(with: .pairedVideo, fileURL: videoURL, options: videoOptions)
          
          print("âœ… iOSåŽŸç”Ÿ: èµ„æºå·²æ·»åŠ åˆ°åˆ›å»ºè¯·æ±‚")
          
        }) { success, error in
          if let error = error {
            let nsError = error as NSError
            print("âŒ iOSåŽŸç”Ÿ: ä¿å­˜å¤±è´¥ - Code: \(nsError.code), \(nsError.localizedDescription)")
            saveError = error
          } else if success {
            print("âœ… iOSåŽŸç”Ÿ: Live Photo ä¿å­˜æˆåŠŸ")
          }
          semaphore.signal()
        }
        
        semaphore.wait()
        
        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try? FileManager.default.removeItem(at: videoURL)
        try? FileManager.default.removeItem(at: coverURL)
        
        DispatchQueue.main.async {
          if let error = saveError {
            result(FlutterError(
              code: "SAVE_FAILED",
              message: error.localizedDescription,
              details: nil
            ))
          } else {
            result(true)
          }
        }
        
      } catch {
        DispatchQueue.main.async {
          print("âŒ iOSåŽŸç”Ÿ: åˆ›å»º Live Photo å¤±è´¥ - \(error.localizedDescription)")
          result(FlutterError(code: "CREATE_FAILED", message: error.localizedDescription, details: nil))
        }
      }
    }
  }
  
  // ðŸ”¥ ä»Žå›¾ç‰‡å¸§åˆ›å»ºè§†é¢‘
  private func createVideoFromFrames(framePaths: [String], outputURL: URL, assetIdentifier: String) throws {
    guard !framePaths.isEmpty else {
      throw NSError(domain: "LivePhotoBridge", code: -1, userInfo: [NSLocalizedDescriptionKey: "No frames provided"])
    }
    
    guard let firstImage = UIImage(contentsOfFile: framePaths[0]) else {
      throw NSError(domain: "LivePhotoBridge", code: -2, userInfo: [NSLocalizedDescriptionKey: "Failed to load first frame"])
    }
    
    let videoSize = firstImage.size
    print("ðŸ“ iOSåŽŸç”Ÿ: è§†é¢‘å°ºå¯¸ - \(videoSize.width) x \(videoSize.height)")
    
    // ðŸ”¥ Live Photo è§†é¢‘è§„èŒƒï¼šå»ºè®® 1-3 ç§’ï¼Œæˆ‘ä»¬ç”¨ 30 å¸§ / 15fps = 2ç§’
    let fps: Int32 = 15 // 15fpsï¼Œ30å¸§æ’­æ”¾2ç§’
    let frameDuration = CMTime(value: 1, timescale: fps)
    
    // åˆ é™¤å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶
    try? FileManager.default.removeItem(at: outputURL)
    
    // åˆ›å»ºè§†é¢‘å†™å…¥å™¨
    let writer = try AVAssetWriter(outputURL: outputURL, fileType: .mov)
    
    // ðŸ”¥ æ·»åŠ  Live Photo å…ƒæ•°æ®
    let metadataItem = AVMutableMetadataItem()
    metadataItem.key = "com.apple.quicktime.content.identifier" as NSString
    metadataItem.keySpace = AVMetadataKeySpace.quickTimeMetadata
    metadataItem.value = assetIdentifier as NSString
    metadataItem.dataType = "com.apple.metadata.datatype.UTF-8"
    writer.metadata = [metadataItem]
    
    let videoSettings: [String: Any] = [
      AVVideoCodecKey: AVVideoCodecType.h264,
      AVVideoWidthKey: Int(videoSize.width),
      AVVideoHeightKey: Int(videoSize.height),
      AVVideoCompressionPropertiesKey: [
        AVVideoAverageBitRateKey: 2000000,
        AVVideoProfileLevelKey: AVVideoProfileLevelH264BaselineAutoLevel
      ]
    ]
    
    let writerInput = AVAssetWriterInput(mediaType: .video, outputSettings: videoSettings)
    writerInput.expectsMediaDataInRealTime = false
    
    let adaptor = AVAssetWriterInputPixelBufferAdaptor(
      assetWriterInput: writerInput,
      sourcePixelBufferAttributes: [
        kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32ARGB,
        kCVPixelBufferWidthKey as String: Int(videoSize.width),
        kCVPixelBufferHeightKey as String: Int(videoSize.height)
      ]
    )
    
    guard writer.canAdd(writerInput) else {
      throw NSError(domain: "LivePhotoBridge", code: -3, userInfo: [NSLocalizedDescriptionKey: "Cannot add writer input"])
    }
    
    writer.add(writerInput)
    writer.startWriting()
    writer.startSession(atSourceTime: .zero)
    
    print("ðŸ“¹ iOSåŽŸç”Ÿ: å¼€å§‹å†™å…¥ \(framePaths.count) å¸§...")
    
    var frameCount: Int64 = 0
    
    for (index, framePath) in framePaths.enumerated() {
      autoreleasepool {
        guard let image = UIImage(contentsOfFile: framePath) else {
          print("âš ï¸ iOSåŽŸç”Ÿ: è·³è¿‡å¸§ \(index) - æ— æ³•åŠ è½½")
          return
        }
        
        guard let pixelBuffer = self.pixelBuffer(from: image, size: videoSize) else {
          print("âš ï¸ iOSåŽŸç”Ÿ: è·³è¿‡å¸§ \(index) - æ— æ³•åˆ›å»º PixelBuffer")
          return
        }
        
        while !writerInput.isReadyForMoreMediaData {
          Thread.sleep(forTimeInterval: 0.01)
        }
        
        let presentationTime = CMTimeMultiply(frameDuration, multiplier: Int32(frameCount))
        
        if adaptor.append(pixelBuffer, withPresentationTime: presentationTime) {
          frameCount += 1
          if index % 10 == 0 {
            print("ðŸ“¹ iOSåŽŸç”Ÿ: å·²å†™å…¥ \(frameCount) å¸§")
          }
        } else {
          print("âš ï¸ iOSåŽŸç”Ÿ: æ·»åŠ å¸§ \(index) å¤±è´¥")
        }
      }
    }
    
    print("ðŸ“¹ iOSåŽŸç”Ÿ: å®Œæˆå†™å…¥ \(frameCount) å¸§ï¼Œæ­£åœ¨ç»“æŸ...")
    
    writerInput.markAsFinished()
    
    let semaphore = DispatchSemaphore(value: 0)
    var finishError: Error?
    
    writer.finishWriting {
      finishError = writer.error
      semaphore.signal()
    }
    
    semaphore.wait()
    
    if let error = finishError {
      throw error
    }
    
    if writer.status != .completed {
      throw NSError(domain: "LivePhotoBridge", code: -4, userInfo: [NSLocalizedDescriptionKey: "Video writing did not complete, status: \(writer.status.rawValue)"])
    }
    
    // éªŒè¯è§†é¢‘æ–‡ä»¶
    let fileSize = try FileManager.default.attributesOfItem(atPath: outputURL.path)[.size] as? UInt64 ?? 0
    print("âœ… iOSåŽŸç”Ÿ: è§†é¢‘åˆ›å»ºæˆåŠŸ - å¤§å°: \(fileSize) bytes, å¸§æ•°: \(frameCount)")
    
    if fileSize == 0 {
      throw NSError(domain: "LivePhotoBridge", code: -5, userInfo: [NSLocalizedDescriptionKey: "Video file is empty"])
    }
  }
  
  // ðŸ”¥ å°† UIImage è½¬æ¢ä¸º CVPixelBuffer
  private func pixelBuffer(from image: UIImage, size: CGSize) -> CVPixelBuffer? {
    let attrs = [
      kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue!,
      kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue!
    ] as CFDictionary
    
    var pixelBuffer: CVPixelBuffer?
    let status = CVPixelBufferCreate(
      kCFAllocatorDefault,
      Int(size.width),
      Int(size.height),
      kCVPixelFormatType_32ARGB,
      attrs,
      &pixelBuffer
    )
    
    guard status == kCVReturnSuccess, let buffer = pixelBuffer else {
      return nil
    }
    
    CVPixelBufferLockBaseAddress(buffer, [])
    defer { CVPixelBufferUnlockBaseAddress(buffer, []) }
    
    let context = CGContext(
      data: CVPixelBufferGetBaseAddress(buffer),
      width: Int(size.width),
      height: Int(size.height),
      bitsPerComponent: 8,
      bytesPerRow: CVPixelBufferGetBytesPerRow(buffer),
      space: CGColorSpaceCreateDeviceRGB(),
      bitmapInfo: CGImageAlphaInfo.noneSkipFirst.rawValue
    )
    
    guard let cgContext = context, let cgImage = image.cgImage else {
      return nil
    }
    
    cgContext.draw(cgImage, in: CGRect(origin: .zero, size: size))
    
    return buffer
  }
}
